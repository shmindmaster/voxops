{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4b4c759",
   "metadata": {},
   "source": [
    "# Azure Voice Live API - Interactive Development Notebook\n",
    "\n",
    "This notebook deconstructs the `voice-live-quickstart.py` script into manageable sections for educational purposes, testing, and development. \n",
    "\n",
    "## Overview\n",
    "\n",
    "The Azure Voice Live API enables real-time voice conversations with AI models. This notebook demonstrates:\n",
    "\n",
    "1. **Setup and Configuration** - Environment variables and authentication\n",
    "2. **Core Classes** - Understanding the main components\n",
    "3. **Audio Processing** - How audio input/output works\n",
    "4. **WebSocket Communication** - Real-time message handling\n",
    "5. **Threading Model** - Concurrent audio processing\n",
    "6. **Complete Integration** - Putting it all together\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Azure Cognitive Services endpoint with Voice Live API access\n",
    "- Python environment with required dependencies\n",
    "- Audio devices (microphone and speakers) for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30573dd7",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies\n",
    "\n",
    "First, let's import all the required libraries and understand what each one does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c225f88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All dependencies imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Core Python libraries\n",
    "import os\n",
    "import uuid\n",
    "import json\n",
    "import time\n",
    "import base64\n",
    "import logging\n",
    "import threading\n",
    "import queue\n",
    "import signal\n",
    "import sys\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "\n",
    "# Audio processing\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "\n",
    "# Azure SDK and authentication\n",
    "from dotenv import load_dotenv\n",
    "from azure.core.credentials import TokenCredential\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Type hints\n",
    "from typing import Dict, Union, Literal, Set\n",
    "from typing_extensions import Iterator, TypedDict, Required\n",
    "\n",
    "# WebSocket communication\n",
    "import websocket\n",
    "from websocket import WebSocketApp\n",
    "\n",
    "print(\"âœ… All dependencies imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b4c1e8",
   "metadata": {},
   "source": [
    "## 2. Configuration and Global Variables\n",
    "\n",
    "Let's set up the configuration and global variables used throughout the application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "975080de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Configuration loaded:\n",
      "  - Endpoint: https://aifoundry825233136833-resource.services.ai.azure.com\n",
      "  - Model: gpt-4o\n",
      "  - API Version: 2025-05-01-preview\n",
      "  - Audio Sample Rate: 24000 Hz\n",
      "  - API Key configured: âŒ\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv(\"./.env\", override=True)\n",
    "\n",
    "# Global variables for thread coordination\n",
    "stop_event = threading.Event()\n",
    "connection_queue = queue.Queue()\n",
    "\n",
    "# Audio configuration\n",
    "AUDIO_SAMPLE_RATE = 24000\n",
    "\n",
    "# Logger setup\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configuration from environment variables\n",
    "AZURE_VOICE_LIVE_ENDPOINT = os.environ.get(\"AZURE_VOICE_LIVE_ENDPOINT\") or \"https://aifoundry825233136833-resource.services.ai.azure.com\"\n",
    "AZURE_VOICE_LIVE_MODEL = os.environ.get(\"AZURE_VOICE_LIVE_MODEL\") or \"gpt-4o\"\n",
    "AZURE_VOICE_LIVE_API_VERSION = os.environ.get(\"AZURE_VOICE_LIVE_API_VERSION\") or \"2025-05-01-preview\"\n",
    "AZURE_VOICE_LIVE_API_KEY = os.environ.get(\"AZURE_VOICE_LIVE_API_KEY\")\n",
    "\n",
    "print(\"ğŸ“‹ Configuration loaded:\")\n",
    "print(f\"  - Endpoint: {AZURE_VOICE_LIVE_ENDPOINT}\")\n",
    "print(f\"  - Model: {AZURE_VOICE_LIVE_MODEL}\")\n",
    "print(f\"  - API Version: {AZURE_VOICE_LIVE_API_VERSION}\")\n",
    "print(f\"  - Audio Sample Rate: {AUDIO_SAMPLE_RATE} Hz\")\n",
    "print(f\"  - API Key configured: {'âœ…' if AZURE_VOICE_LIVE_API_KEY else 'âŒ'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98979862",
   "metadata": {},
   "source": [
    "## 3. WebSocket Connection Management\n",
    "The WebSocket endpoint for the voice live API is `wss://<your-ai-foundry-resource-name>.cognitiveservices.azure.com/voice-live/realtime?api-version=2025-05-01-preview`. The endpoint is the same for all models. The only difference is the required model query parameter.\n",
    "\n",
    "For example, an endpoint for a resource with a custom domain would be `wss://<your-ai-foundry-resource-name>.cognitiveservices.azure.com/voice-live/realtime?api-version=2025-05-01-preview&model=gpt-4o-mini-realtime-preview`\n",
    "\n",
    "The `VoiceLiveConnection` class handles the WebSocket connection to the Azure Voice Live API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f9343d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… VoiceLiveConnection class defined\n"
     ]
    }
   ],
   "source": [
    "class VoiceLiveConnection:\n",
    "    \"\"\"\n",
    "    Manages WebSocket connection to Azure Voice Live API.\n",
    "    \n",
    "    Features:\n",
    "    - Asynchronous message handling\n",
    "    - Thread-safe message queue\n",
    "    - Connection state management\n",
    "    - Error handling and logging\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, url: str, headers: dict) -> None:\n",
    "        self._url = url\n",
    "        self._headers = headers\n",
    "        self._ws = None\n",
    "        self._message_queue = queue.Queue()\n",
    "        self._connected = False\n",
    "\n",
    "    def connect(self) -> None:\n",
    "        \"\"\"Establish WebSocket connection with event handlers.\"\"\"\n",
    "        \n",
    "        def on_message(ws, message):\n",
    "            \"\"\"Handle incoming messages by adding them to the queue.\"\"\"\n",
    "            self._message_queue.put(message)\n",
    "        \n",
    "        def on_error(ws, error):\n",
    "            \"\"\"Handle WebSocket errors.\"\"\"\n",
    "            logger.error(f\"WebSocket error: {error}\")\n",
    "        \n",
    "        def on_close(ws, close_status_code, close_msg):\n",
    "            \"\"\"Handle connection closure.\"\"\"\n",
    "            logger.info(\"WebSocket connection closed\")\n",
    "            self._connected = False\n",
    "        \n",
    "        def on_open(ws):\n",
    "            \"\"\"Handle successful connection.\"\"\"\n",
    "            logger.info(\"WebSocket connection opened\")\n",
    "            self._connected = True\n",
    "\n",
    "        # Create WebSocket app with event handlers\n",
    "        self._ws = websocket.WebSocketApp(\n",
    "            self._url,\n",
    "            header=self._headers,\n",
    "            on_message=on_message,\n",
    "            on_error=on_error,\n",
    "            on_close=on_close,\n",
    "            on_open=on_open\n",
    "        )\n",
    "        \n",
    "        # Start WebSocket in a separate thread\n",
    "        self._ws_thread = threading.Thread(target=self._ws.run_forever)\n",
    "        self._ws_thread.daemon = True\n",
    "        self._ws_thread.start()\n",
    "        \n",
    "        # Wait for connection to be established\n",
    "        timeout = 10  # seconds\n",
    "        start_time = time.time()\n",
    "        while not self._connected and time.time() - start_time < timeout:\n",
    "            time.sleep(0.1)\n",
    "        \n",
    "        if not self._connected:\n",
    "            raise ConnectionError(\"Failed to establish WebSocket connection\")\n",
    "\n",
    "    def recv(self) -> str:\n",
    "        \"\"\"Receive a message from the queue (non-blocking with timeout).\"\"\"\n",
    "        try:\n",
    "            return self._message_queue.get(timeout=1)\n",
    "        except queue.Empty:\n",
    "            return None\n",
    "\n",
    "    def send(self, message: str) -> None:\n",
    "        \"\"\"Send a message through the WebSocket.\"\"\"\n",
    "        if self._ws and self._connected:\n",
    "            self._ws.send(message)\n",
    "\n",
    "    def close(self) -> None:\n",
    "        \"\"\"Close the WebSocket connection.\"\"\"\n",
    "        if self._ws:\n",
    "            self._ws.close()\n",
    "            self._connected = False\n",
    "\n",
    "print(\"âœ… VoiceLiveConnection class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281b32e6",
   "metadata": {},
   "source": [
    "## 4. Azure Voice Live Client\n",
    "\n",
    "The main client class that handles authentication and connection setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79ef66e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AzureVoiceLive client class defined\n"
     ]
    }
   ],
   "source": [
    "class AzureVoiceLive:\n",
    "    \"\"\"\n",
    "    Main client for Azure Voice Live API.\n",
    "    \n",
    "    Handles:\n",
    "    - Authentication (API key or token-based)\n",
    "    - Connection management\n",
    "    - URL construction for WebSocket endpoint\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        azure_endpoint: str | None = None,\n",
    "        api_version: str | None = None,\n",
    "        token: str | None = None,\n",
    "        api_key: str | None = None,\n",
    "    ) -> None:\n",
    "        self._azure_endpoint = azure_endpoint\n",
    "        self._api_version = api_version\n",
    "        self._token = token\n",
    "        self._api_key = api_key\n",
    "        self._connection = None\n",
    "\n",
    "    def connect(self, model: str) -> VoiceLiveConnection:\n",
    "        \"\"\"\n",
    "        Create a connection to the Voice Live API.\n",
    "        \n",
    "        Args:\n",
    "            model: The AI model to use (e.g., 'gpt-4o')\n",
    "            \n",
    "        Returns:\n",
    "            VoiceLiveConnection: Ready-to-use connection object\n",
    "        \"\"\"\n",
    "        # if self._connection is not None:\n",
    "        #     raise ValueError(\"Already connected to the Voice Live API.\")\n",
    "        if not model:\n",
    "            raise ValueError(\"Model name is required.\")\n",
    "\n",
    "        # Convert HTTPS endpoint to WSS for WebSocket\n",
    "        azure_ws_endpoint = self._azure_endpoint.rstrip('/').replace(\"https://\", \"wss://\")\n",
    "\n",
    "        # Construct WebSocket URL\n",
    "        url = f\"{azure_ws_endpoint}/voice-live/realtime?api-version={self._api_version}&model={model}\"\n",
    "\n",
    "        # Setup authentication headers\n",
    "        auth_header = {\"Authorization\": f\"Bearer {self._token}\"} if self._token else {\"api-key\": self._api_key}\n",
    "        request_id = uuid.uuid4()\n",
    "        headers = {\"x-ms-client-request-id\": str(request_id), **auth_header}\n",
    "\n",
    "        # Create and connect\n",
    "        self._connection = VoiceLiveConnection(url, headers)\n",
    "        self._connection.connect()\n",
    "        return self._connection\n",
    "\n",
    "print(\"âœ… AzureVoiceLive client class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31dba1f",
   "metadata": {},
   "source": [
    "## 5. Audio Processing Components\n",
    "\n",
    "The `AudioPlayerAsync` class handles real-time audio playback with buffering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0df2911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AudioPlayerAsync class defined\n"
     ]
    }
   ],
   "source": [
    "class AudioPlayerAsync:\n",
    "    \"\"\"\n",
    "    Asynchronous audio player with buffering for real-time playback.\n",
    "    \n",
    "    Features:\n",
    "    - Thread-safe audio queue\n",
    "    - Real-time streaming playback\n",
    "    - Automatic start/stop management\n",
    "    - Low-latency audio processing\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.queue = deque()\n",
    "        self.lock = threading.Lock()\n",
    "        self.stream = sd.OutputStream(\n",
    "            callback=self.callback,\n",
    "            samplerate=AUDIO_SAMPLE_RATE,\n",
    "            channels=1,\n",
    "            dtype=np.int16,\n",
    "            blocksize=2400,  # ~100ms at 24kHz\n",
    "        )\n",
    "        self.playing = False\n",
    "\n",
    "    def callback(self, outdata, frames, time, status):\n",
    "        \"\"\"\n",
    "        Audio callback function called by sounddevice.\n",
    "        \n",
    "        This function is called in real-time by the audio system\n",
    "        and must be very efficient to avoid dropouts.\n",
    "        \"\"\"\n",
    "        if status:\n",
    "            logger.warning(f\"Stream status: {status}\")\n",
    "            \n",
    "        with self.lock:\n",
    "            data = np.empty(0, dtype=np.int16)\n",
    "            \n",
    "            # Fill the output buffer from our queue\n",
    "            while len(data) < frames and len(self.queue) > 0:\n",
    "                item = self.queue.popleft()\n",
    "                frames_needed = frames - len(data)\n",
    "                data = np.concatenate((data, item[:frames_needed]))\n",
    "                \n",
    "                # If we have leftover data, put it back\n",
    "                if len(item) > frames_needed:\n",
    "                    self.queue.appendleft(item[frames_needed:])\n",
    "            \n",
    "            # Pad with silence if we don't have enough data\n",
    "            if len(data) < frames:\n",
    "                data = np.concatenate((data, np.zeros(frames - len(data), dtype=np.int16)))\n",
    "                \n",
    "        outdata[:] = data.reshape(-1, 1)\n",
    "\n",
    "    def add_data(self, data: bytes):\n",
    "        \"\"\"Add audio data to the playback queue.\"\"\"\n",
    "        with self.lock:\n",
    "            np_data = np.frombuffer(data, dtype=np.int16)\n",
    "            self.queue.append(np_data)\n",
    "            \n",
    "            # Auto-start playback if we have data\n",
    "            if not self.playing and len(self.queue) > 0:\n",
    "                self.start()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start audio playback.\"\"\"\n",
    "        if not self.playing:\n",
    "            self.playing = True\n",
    "            self.stream.start()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop audio playback and clear buffer.\"\"\"\n",
    "        with self.lock:\n",
    "            self.queue.clear()\n",
    "        self.playing = False\n",
    "        self.stream.stop()\n",
    "\n",
    "    def terminate(self):\n",
    "        \"\"\"Terminate the audio player and release resources.\"\"\"\n",
    "        with self.lock:\n",
    "            self.queue.clear()\n",
    "        self.stream.stop()\n",
    "        self.stream.close()\n",
    "\n",
    "print(\"âœ… AudioPlayerAsync class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7a2c84",
   "metadata": {},
   "source": [
    "## 6. Audio Input Processing\n",
    "\n",
    "Function to capture microphone input and send it to the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c51023df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Audio input function defined\n"
     ]
    }
   ],
   "source": [
    "def listen_and_send_audio(connection: VoiceLiveConnection) -> None:\n",
    "    \"\"\"\n",
    "    Capture audio from microphone and send to Voice Live API.\n",
    "    \n",
    "    This function runs in a separate thread and continuously:\n",
    "    1. Reads audio from the microphone\n",
    "    2. Encodes it as base64\n",
    "    3. Sends it to the API via WebSocket\n",
    "    \n",
    "    Args:\n",
    "        connection: Active VoiceLiveConnection instance\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting audio stream ...\")\n",
    "\n",
    "    # Create audio input stream\n",
    "    stream = sd.InputStream(\n",
    "        channels=1, \n",
    "        samplerate=AUDIO_SAMPLE_RATE, \n",
    "        dtype=\"int16\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        stream.start()\n",
    "        \n",
    "        # Read audio in 20ms chunks (480 samples at 24kHz)\n",
    "        read_size = int(AUDIO_SAMPLE_RATE * 0.02)\n",
    "        \n",
    "        while not stop_event.is_set():\n",
    "            if stream.read_available >= read_size:\n",
    "                # Read audio data\n",
    "                data, _ = stream.read(read_size)\n",
    "                \n",
    "                # Encode as base64\n",
    "                audio = base64.b64encode(data).decode(\"utf-8\")\n",
    "                \n",
    "                # Create API message\n",
    "                param = {\n",
    "                    \"type\": \"input_audio_buffer.append\", \n",
    "                    \"audio\": audio, \n",
    "                    \"event_id\": \"\"\n",
    "                }\n",
    "                \n",
    "                # Send to API\n",
    "                data_json = json.dumps(param)\n",
    "                connection.send(data_json)\n",
    "            else:\n",
    "                time.sleep(0.001)  # Small sleep to prevent busy waiting\n",
    "                \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Audio stream interrupted. {e}\")\n",
    "    finally:\n",
    "        stream.stop()\n",
    "        stream.close()\n",
    "        logger.info(\"Audio stream closed.\")\n",
    "\n",
    "print(\"âœ… Audio input function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f726f6d0",
   "metadata": {},
   "source": [
    "## 7. Audio Output Processing\n",
    "\n",
    "Function to receive audio from the API and handle playback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0130a222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Audio output function defined\n"
     ]
    }
   ],
   "source": [
    "def receive_audio_and_playback(connection: VoiceLiveConnection) -> None:\n",
    "    \"\"\"\n",
    "    Receive messages from Voice Live API and handle audio playback.\n",
    "    \n",
    "    This function runs in a separate thread and handles:\n",
    "    1. Receiving WebSocket messages from the API\n",
    "    2. Processing different event types\n",
    "    3. Playing back audio responses\n",
    "    4. Managing conversation state\n",
    "    \n",
    "    Args:\n",
    "        connection: Active VoiceLiveConnection instance\n",
    "    \"\"\"\n",
    "    last_audio_item_id = None\n",
    "    audio_player = AudioPlayerAsync()\n",
    "\n",
    "    logger.info(\"Starting audio playback ...\")\n",
    "    \n",
    "    try:\n",
    "        while not stop_event.is_set():\n",
    "            # Receive message from API\n",
    "            raw_event = connection.recv()\n",
    "            if raw_event is None:\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                event = json.loads(raw_event)\n",
    "                event_type = event.get(\"type\")\n",
    "                print(f\"Received event: {event_type}\")\n",
    "\n",
    "                # Handle different event types\n",
    "                if event_type == \"session.created\":\n",
    "                    session = event.get(\"session\")\n",
    "                    logger.info(f\"Session created: {session.get('id')}\")\n",
    "\n",
    "                elif event_type == \"response.audio.delta\":\n",
    "                    # New audio data from AI response\n",
    "                    if event.get(\"item_id\") != last_audio_item_id:\n",
    "                        last_audio_item_id = event.get(\"item_id\")\n",
    "\n",
    "                    # Decode and play audio\n",
    "                    bytes_data = base64.b64decode(event.get(\"delta\", \"\"))\n",
    "                    if bytes_data:\n",
    "                        logger.debug(f\"Received audio data of length: {len(bytes_data)}\")   \n",
    "                        audio_player.add_data(bytes_data)\n",
    "\n",
    "                elif event_type == \"input_audio_buffer.speech_started\":\n",
    "                    # User started speaking - stop AI playback\n",
    "                    print(\"ğŸ¤ Speech started\")\n",
    "                    audio_player.stop()\n",
    "\n",
    "                elif event_type == \"error\":\n",
    "                    # Handle API errors\n",
    "                    error_details = event.get(\"error\", {})\n",
    "                    error_type = error_details.get(\"type\", \"Unknown\")\n",
    "                    error_code = error_details.get(\"code\", \"Unknown\")\n",
    "                    error_message = error_details.get(\"message\", \"No message provided\")\n",
    "                    raise ValueError(f\"Error received: Type={error_type}, Code={error_code}, Message={error_message}\")\n",
    "                    \n",
    "            except json.JSONDecodeError as e:\n",
    "                logger.error(f\"Failed to parse JSON event: {e}\")\n",
    "                continue\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in audio playback: {e}\")\n",
    "    finally:\n",
    "        audio_player.terminate()\n",
    "        logger.info(\"Playback done.\")\n",
    "\n",
    "print(\"âœ… Audio output function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49ce490",
   "metadata": {},
   "source": [
    "## 8. User Input Management\n",
    "\n",
    "Function to handle keyboard input for graceful shutdown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99734c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… User input function defined\n"
     ]
    }
   ],
   "source": [
    "def read_keyboard_and_quit() -> None:\n",
    "    \"\"\"\n",
    "    Monitor keyboard input for quit command.\n",
    "    \n",
    "    This function runs in a separate thread and waits for the user\n",
    "    to type 'q' to gracefully shutdown the application.\n",
    "    \"\"\"\n",
    "    print(\"Press 'q' and Enter to quit the chat.\")\n",
    "    \n",
    "    while not stop_event.is_set():\n",
    "        try:\n",
    "            user_input = input()\n",
    "            if user_input.strip().lower() == 'q':\n",
    "                print(\"Quitting the chat...\")\n",
    "                stop_event.set()\n",
    "                break\n",
    "        except EOFError:\n",
    "            # Handle case where input is interrupted\n",
    "            break\n",
    "\n",
    "print(\"âœ… User input function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a046d0",
   "metadata": {},
   "source": [
    "## 9. Session Configuration\n",
    "\n",
    "Now let's create the session configuration that defines how the AI should behave:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9c8f812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Session configuration created\n",
      "   - Voice: en-US-Ava:DragonHDLatestNeural\n",
      "   - VAD Type: azure_semantic_vad\n",
      "   - Noise Reduction: azure_deep_noise_suppression\n",
      "   - Echo Cancellation: server_echo_cancellation\n"
     ]
    }
   ],
   "source": [
    "# Session configuration for the Voice Live API\n",
    "session_config = {\n",
    "    \"type\": \"session.update\",\n",
    "    \"session\": {\n",
    "        # Basic AI behavior\n",
    "        \"instructions\": \"You are a helpful AI assistant responding in natural, engaging language.\",\n",
    "        \n",
    "        # Voice Activity Detection (VAD) settings\n",
    "        \"turn_detection\": {\n",
    "            \"type\": \"azure_semantic_vad\",\n",
    "            \"threshold\": 0.3,  # Sensitivity for detecting speech\n",
    "            \"prefix_padding_ms\": 200,  # Keep audio before speech starts\n",
    "            \"silence_duration_ms\": 200,  # How long to wait for silence\n",
    "            \"remove_filler_words\": False,  # Keep \"um\", \"uh\", etc.\n",
    "            \"end_of_utterance_detection\": {\n",
    "                \"model\": \"semantic_detection_v1\",\n",
    "                \"threshold\": 0.01,  # When to consider speech finished\n",
    "                \"timeout\": 2,  # Max time to wait for continuation\n",
    "            },\n",
    "        },\n",
    "        \n",
    "        # Audio preprocessing\n",
    "        \"input_audio_noise_reduction\": {\n",
    "            \"type\": \"azure_deep_noise_suppression\"  # Remove background noise\n",
    "        },\n",
    "        \"input_audio_echo_cancellation\": {\n",
    "            \"type\": \"server_echo_cancellation\"  # Prevent feedback loops\n",
    "        },\n",
    "        \n",
    "        # AI voice settings\n",
    "        \"voice\": {\n",
    "            \"name\": \"en-US-Ava:DragonHDLatestNeural\",  # High-quality neural voice\n",
    "            \"type\": \"azure-standard\",\n",
    "            \"temperature\": 0.8,  # Controls response creativity/randomness\n",
    "        },\n",
    "    },\n",
    "    \"event_id\": \"\"\n",
    "}\n",
    "\n",
    "print(\"âœ… Session configuration created\")\n",
    "print(f\"   - Voice: {session_config['session']['voice']['name']}\")\n",
    "print(f\"   - VAD Type: {session_config['session']['turn_detection']['type']}\")\n",
    "print(f\"   - Noise Reduction: {session_config['session']['input_audio_noise_reduction']['type']}\")\n",
    "print(f\"   - Echo Cancellation: {session_config['session']['input_audio_echo_cancellation']['type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429d420f",
   "metadata": {},
   "source": [
    "## 10. Client Setup and Authentication\n",
    "\n",
    "Let's create the client and establish a connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8000172f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Using token-based authentication\n",
      "âœ… Azure Voice Live client created successfully\n",
      "   - Authentication: token\n",
      "   - Endpoint: https://aifoundry825233136833-resource.services.ai.azure.com\n",
      "   - Model: gpt-4o\n"
     ]
    }
   ],
   "source": [
    "# Setup logging for this session\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Create logs directory if it doesn't exist\n",
    "import os\n",
    "if not os.path.exists('logs'):\n",
    "    os.makedirs('logs')\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename=f'logs/{timestamp}_voicelive_notebook.log',\n",
    "    filemode=\"w\",\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s:%(name)s:%(levelname)s:%(message)s'\n",
    ")\n",
    "\n",
    "# Setup authentication - prefer token-based auth\n",
    "credential = DefaultAzureCredential()\n",
    "scopes = \"https://ai.azure.com/.default\"\n",
    "\n",
    "try:\n",
    "    token = credential.get_token(scopes)\n",
    "    auth_method = \"token\"\n",
    "    print(\"âœ… Using token-based authentication\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Token auth failed: {e}\")\n",
    "    print(\"ğŸ”‘ Falling back to API key authentication\")\n",
    "    auth_method = \"api_key\"\n",
    "\n",
    "# Create the client\n",
    "client_kwargs = {\n",
    "    \"azure_endpoint\": AZURE_VOICE_LIVE_ENDPOINT,\n",
    "    \"api_version\": AZURE_VOICE_LIVE_API_VERSION,\n",
    "}\n",
    "\n",
    "if auth_method == \"token\":\n",
    "    client_kwargs[\"token\"] = token.token\n",
    "else:\n",
    "    client_kwargs[\"api_key\"] = AZURE_VOICE_LIVE_API_KEY\n",
    "\n",
    "client = AzureVoiceLive(**client_kwargs)\n",
    "\n",
    "print(f\"âœ… Azure Voice Live client created successfully\")\n",
    "print(f\"   - Authentication: {auth_method}\")\n",
    "print(f\"   - Endpoint: {AZURE_VOICE_LIVE_ENDPOINT}\")\n",
    "print(f\"   - Model: {AZURE_VOICE_LIVE_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daefbd2f",
   "metadata": {},
   "source": [
    "## 11. Test Connection (Optional)\n",
    "\n",
    "Let's test the connection without starting the full voice chat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "342550c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”Œ Testing connection...\n",
      "âœ… Connection test successful!\n",
      "ğŸ”Œ Test connection closed\n"
     ]
    }
   ],
   "source": [
    "# Test connection (optional - uncomment to run)\n",
    "# This will establish a connection and immediately close it\n",
    "\n",
    "try:\n",
    "    print(\"ğŸ”Œ Testing connection...\")\n",
    "    test_connection = client.connect(model=AZURE_VOICE_LIVE_MODEL)\n",
    "    print(\"âœ… Connection test successful!\")\n",
    "    test_connection.close()\n",
    "    print(\"ğŸ”Œ Test connection closed\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Connection test failed: {e}\")\n",
    "\n",
    "# print(\"â„¹ï¸  Connection test code ready (uncomment to run)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768752c1",
   "metadata": {},
   "source": [
    "## 12. Main Voice Chat Application\n",
    "\n",
    "Now let's put it all together to create the complete voice chat experience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58a88aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Main voice chat function defined\n"
     ]
    }
   ],
   "source": [
    "def run_voice_chat():\n",
    "    \"\"\"\n",
    "    Main function to run the complete voice chat application.\n",
    "    \n",
    "    This orchestrates:\n",
    "    1. Connection establishment\n",
    "    2. Session configuration\n",
    "    3. Thread management for audio I/O\n",
    "    4. Graceful shutdown\n",
    "    \"\"\"\n",
    "    global stop_event\n",
    "    \n",
    "    # Reset the stop event for a fresh start\n",
    "    stop_event.clear()\n",
    "    \n",
    "    try:\n",
    "        print(\"ğŸš€ Starting Voice Live chat application...\")\n",
    "        \n",
    "        # 1. Connect to the API\n",
    "        if hasattr(client, '_connection'):\n",
    "            connection = client._connection\n",
    "        else:\n",
    "            connection = client.connect(model=AZURE_VOICE_LIVE_MODEL)\n",
    "        print(\"âœ… Connected to Voice Live API\")\n",
    "        \n",
    "        # 2. Send session configuration\n",
    "        connection.send(json.dumps(session_config))\n",
    "        print(\"âœ… Session configuration sent\")\n",
    "        \n",
    "        # 3. Create and start threads\n",
    "        print(\"ğŸ§µ Starting threads...\")\n",
    "        send_thread = threading.Thread(\n",
    "            target=listen_and_send_audio, \n",
    "            args=(connection,),\n",
    "            name=\"AudioInput\"\n",
    "        )\n",
    "        receive_thread = threading.Thread(\n",
    "            target=receive_audio_and_playback, \n",
    "            args=(connection,),\n",
    "            name=\"AudioOutput\"\n",
    "        )\n",
    "        keyboard_thread = threading.Thread(\n",
    "            target=read_keyboard_and_quit,\n",
    "            name=\"KeyboardInput\"\n",
    "        )\n",
    "\n",
    "        # Start all threads\n",
    "        send_thread.start()\n",
    "        receive_thread.start()\n",
    "        keyboard_thread.start()\n",
    "        \n",
    "        print(\"ğŸ™ï¸  Voice chat is now active!\")\n",
    "        print(\"ğŸ’¬ You can start speaking...\")\n",
    "        print(\"âŒ¨ï¸  Type 'q' and press Enter to quit\")\n",
    "        \n",
    "        # 4. Wait for user to quit\n",
    "        keyboard_thread.join()\n",
    "        \n",
    "        # 5. Graceful shutdown\n",
    "        print(\"ğŸ›‘ Shutting down...\")\n",
    "        stop_event.set()\n",
    "        \n",
    "        # Wait for threads to finish (with timeout)\n",
    "        send_thread.join(timeout=2)\n",
    "        receive_thread.join(timeout=2)\n",
    "        \n",
    "        # Close connection\n",
    "        connection.close()\n",
    "        print(\"âœ… Voice chat ended successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in voice chat: {e}\")\n",
    "        stop_event.set()\n",
    "        if 'connection' in locals():\n",
    "            connection.close()\n",
    "\n",
    "print(\"âœ… Main voice chat function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad034a6",
   "metadata": {},
   "source": [
    "## 13. Run the Voice Chat\n",
    "\n",
    "**âš ï¸ Important:** Make sure you have:\n",
    "1. A microphone and speakers/headphones connected\n",
    "2. Azure Voice Live API credentials configured\n",
    "3. A quiet environment for testing\n",
    "\n",
    "Uncomment and run the cell below to start the voice chat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8984513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting Voice Live chat application...\n",
      "âœ… Connected to Voice Live API\n",
      "âœ… Session configuration sent\n",
      "ğŸ§µ Starting threads...\n",
      "Press 'q' and Enter to quit the chat.\n",
      "ğŸ™ï¸  Voice chat is now active!\n",
      "ğŸ’¬ You can start speaking...\n",
      "âŒ¨ï¸  Type 'q' and press Enter to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received event: session.created\n",
      "Quitting the chat...\n",
      "ğŸ›‘ Shutting down...\n",
      "âœ… Voice chat ended successfully\n",
      "ğŸ¯ Ready to start voice chat!\n",
      "ğŸ“‹ To run: uncomment the line above and execute this cell\n",
      "ğŸ™ï¸  Make sure your microphone and speakers are working\n",
      "ğŸ“ Check the logs directory for detailed logging\n"
     ]
    }
   ],
   "source": [
    "# Run the voice chat application\n",
    "# Uncomment the line below to start the chat\n",
    "run_voice_chat()\n",
    "\n",
    "print(\"ğŸ¯ Ready to start voice chat!\")\n",
    "print(\"ğŸ“‹ To run: uncomment the line above and execute this cell\")\n",
    "print(\"ğŸ™ï¸  Make sure your microphone and speakers are working\")\n",
    "print(\"ğŸ“ Check the logs directory for detailed logging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88406c04",
   "metadata": {},
   "source": [
    "## 14. Development & Testing Utilities\n",
    "\n",
    "Here are some utility functions for development and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "634ea8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Development utilities loaded:\n",
      "  - check_audio_devices(): Check available audio devices\n",
      "  - test_microphone(duration=3): Test microphone input\n",
      "  - create_custom_session_config(): Create custom configurations\n",
      "  - view_logs(): View recent log entries\n"
     ]
    }
   ],
   "source": [
    "# Development and testing utilities\n",
    "\n",
    "def check_audio_devices():\n",
    "    \"\"\"Check available audio input and output devices.\"\"\"\n",
    "    print(\"ğŸ¤ Available Audio Input Devices:\")\n",
    "    for i, device in enumerate(sd.query_devices()):\n",
    "        if device['max_input_channels'] > 0:\n",
    "            print(f\"  {i}: {device['name']} (inputs: {device['max_input_channels']})\")\n",
    "    \n",
    "    print(\"\\nğŸ”Š Available Audio Output Devices:\")\n",
    "    for i, device in enumerate(sd.query_devices()):\n",
    "        if device['max_output_channels'] > 0:\n",
    "            print(f\"  {i}: {device['name']} (outputs: {device['max_output_channels']})\")\n",
    "    \n",
    "    print(f\"\\nğŸ›ï¸  Default Input Device: {sd.query_devices(sd.default.device[0])['name']}\")\n",
    "    print(f\"ğŸ›ï¸  Default Output Device: {sd.query_devices(sd.default.device[1])['name']}\")\n",
    "\n",
    "def test_microphone(duration=3):\n",
    "    \"\"\"Test microphone input for a few seconds.\"\"\"\n",
    "    print(f\"ğŸ¤ Testing microphone for {duration} seconds...\")\n",
    "    print(\"ğŸ’¬ Please speak into your microphone...\")\n",
    "    \n",
    "    def callback(indata, frames, time, status):\n",
    "        volume_norm = np.linalg.norm(indata) * 10\n",
    "        print(f\"ğŸ“Š Volume level: {'â–ˆ' * int(volume_norm)}\")\n",
    "    \n",
    "    with sd.InputStream(callback=callback, channels=1, samplerate=AUDIO_SAMPLE_RATE):\n",
    "        sd.sleep(duration * 1000)\n",
    "    \n",
    "    print(\"âœ… Microphone test complete\")\n",
    "\n",
    "def create_custom_session_config(\n",
    "    instructions=\"You are a helpful AI assistant.\",\n",
    "    voice_name=\"en-US-Ava:DragonHDLatestNeural\",\n",
    "    temperature=0.8,\n",
    "    vad_threshold=0.3\n",
    "):\n",
    "    \"\"\"Create a custom session configuration.\"\"\"\n",
    "    return {\n",
    "        \"type\": \"session.update\",\n",
    "        \"session\": {\n",
    "            \"instructions\": instructions,\n",
    "            \"turn_detection\": {\n",
    "                \"type\": \"azure_semantic_vad\",\n",
    "                \"threshold\": vad_threshold,\n",
    "                \"prefix_padding_ms\": 200,\n",
    "                \"silence_duration_ms\": 200,\n",
    "                \"remove_filler_words\": False,\n",
    "                \"end_of_utterance_detection\": {\n",
    "                    \"model\": \"semantic_detection_v1\",\n",
    "                    \"threshold\": 0.01,\n",
    "                    \"timeout\": 2,\n",
    "                },\n",
    "            },\n",
    "            \"input_audio_noise_reduction\": {\n",
    "                \"type\": \"azure_deep_noise_suppression\"\n",
    "            },\n",
    "            \"input_audio_echo_cancellation\": {\n",
    "                \"type\": \"server_echo_cancellation\"\n",
    "            },\n",
    "            \"voice\": {\n",
    "                \"name\": voice_name,\n",
    "                \"type\": \"azure-standard\",\n",
    "                \"temperature\": temperature,\n",
    "            },\n",
    "        },\n",
    "        \"event_id\": \"\"\n",
    "    }\n",
    "\n",
    "def view_logs():\n",
    "    \"\"\"View the most recent log file.\"\"\"\n",
    "    import glob\n",
    "    log_files = glob.glob(\"logs/*.log\")\n",
    "    if log_files:\n",
    "        latest_log = max(log_files, key=os.path.getctime)\n",
    "        print(f\"ğŸ“ Latest log file: {latest_log}\")\n",
    "        with open(latest_log, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            print(\"ğŸ“„ Last 20 lines:\")\n",
    "            for line in lines[-20:]:\n",
    "                print(line.strip())\n",
    "    else:\n",
    "        print(\"ğŸ“ No log files found\")\n",
    "\n",
    "print(\"âœ… Development utilities loaded:\")\n",
    "print(\"  - check_audio_devices(): Check available audio devices\")\n",
    "print(\"  - test_microphone(duration=3): Test microphone input\")\n",
    "print(\"  - create_custom_session_config(): Create custom configurations\")\n",
    "print(\"  - view_logs(): View recent log entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8460e6",
   "metadata": {},
   "source": [
    "## 15. Example Tests\n",
    "\n",
    "Run these cells to test individual components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d512bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Test 1: Audio device check (uncomment to run)\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Check audio devices\n",
    "# Uncomment to run:\n",
    "# check_audio_devices()\n",
    "\n",
    "print(\"ğŸ” Test 1: Audio device check (uncomment to run)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c609e017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤ Test 2: Microphone test (uncomment to run)\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Test microphone input\n",
    "# Uncomment to run:\n",
    "# test_microphone(duration=3)\n",
    "\n",
    "print(\"ğŸ¤ Test 2: Microphone test (uncomment to run)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114c30af",
   "metadata": {},
   "source": [
    "## 16. Troubleshooting & Tips\n",
    "\n",
    "### Common Issues and Solutions:\n",
    "\n",
    "1. **Authentication Errors**\n",
    "   - Ensure your Azure credentials are configured\n",
    "   - Check that your API key is valid\n",
    "   - Verify the endpoint URL is correct\n",
    "\n",
    "2. **Audio Issues**\n",
    "   - Run `check_audio_devices()` to verify device availability\n",
    "   - Test microphone with `test_microphone()`\n",
    "   - Check system audio permissions for the application\n",
    "\n",
    "3. **Connection Problems**\n",
    "   - Verify internet connectivity\n",
    "   - Check firewall settings for WebSocket connections\n",
    "   - Ensure the endpoint supports Voice Live API\n",
    "\n",
    "4. **Performance Optimization**\n",
    "   - Use headphones to prevent echo/feedback\n",
    "   - Minimize background noise\n",
    "   - Adjust VAD threshold in session config\n",
    "\n",
    "### Voice Live API Features:\n",
    "\n",
    "- **Real-time Voice Interaction**: Low-latency conversation with AI\n",
    "- **Advanced VAD**: Semantic voice activity detection\n",
    "- **Noise Suppression**: Built-in noise reduction and echo cancellation\n",
    "- **Neural Voices**: High-quality text-to-speech synthesis\n",
    "- **Flexible Configuration**: Customizable session parameters\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Experiment with Configuration**: Try different voices, VAD settings, and instructions\n",
    "2. **Add Custom Logic**: Implement conversation tracking, session management\n",
    "3. **Integration**: Connect to your applications and workflows\n",
    "4. **Monitoring**: Add application insights and performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2d8edf",
   "metadata": {},
   "source": [
    "## 17. Debugging & Diagnostics\n",
    "\n",
    "Let's run some diagnostics to understand why the voice chat isn't working properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4857980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Checking audio device configuration...\n",
      "ğŸ¤ Available Audio Input Devices:\n",
      "  1: Jinâ€™s AirPods Pro (inputs: 1)\n",
      "  4: HD Pro Webcam C920 (inputs: 2)\n",
      "  6: Jabra Link 380 (inputs: 1)\n",
      "  7: MacBook Pro Microphone (inputs: 1)\n",
      "  9: Microsoft Teams Audio (inputs: 1)\n",
      "\n",
      "ğŸ”Š Available Audio Output Devices:\n",
      "  0: LG ULTRAWIDE (outputs: 2)\n",
      "  2: Jinâ€™s AirPods Pro (outputs: 2)\n",
      "  3: C49RG9x (outputs: 2)\n",
      "  5: Jabra Link 380 (outputs: 2)\n",
      "  8: MacBook Pro Speakers (outputs: 2)\n",
      "  9: Microsoft Teams Audio (outputs: 1)\n",
      "\n",
      "ğŸ›ï¸  Default Input Device: Jinâ€™s AirPods Pro\n",
      "ğŸ›ï¸  Default Output Device: Jinâ€™s AirPods Pro\n",
      "\n",
      "============================================================\n",
      "ğŸ¤ Testing microphone for 3 seconds...\n",
      "Please speak into your microphone!\n",
      "ğŸ¤ Testing microphone for 3 seconds...\n",
      "ğŸ’¬ Please speak into your microphone...\n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: â–ˆâ–ˆâ–ˆ\n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "ğŸ“Š Volume level: \n",
      "âœ… Microphone test complete\n"
     ]
    }
   ],
   "source": [
    "# First, let's check your audio devices\n",
    "print(\"ğŸ” Checking audio device configuration...\")\n",
    "check_audio_devices()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ¤ Testing microphone for 3 seconds...\")\n",
    "print(\"Please speak into your microphone!\")\n",
    "test_microphone(duration=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f7f244e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Debug voice chat function created\n"
     ]
    }
   ],
   "source": [
    "def run_voice_chat_debug():\n",
    "    \"\"\"\n",
    "    Enhanced voice chat function with better debugging and error handling.\n",
    "    \"\"\"\n",
    "    global stop_event\n",
    "    \n",
    "    # Reset the stop event for a fresh start\n",
    "    stop_event.clear()\n",
    "    \n",
    "    try:\n",
    "        print(\"ğŸš€ Starting Voice Live chat application (DEBUG MODE)...\")\n",
    "        \n",
    "        # 1. Connect to the API\n",
    "        connection = client.connect(model=AZURE_VOICE_LIVE_MODEL)\n",
    "        print(\"âœ… Connected to Voice Live API\")\n",
    "        \n",
    "        # 2. Send session configuration\n",
    "        connection.send(json.dumps(session_config))\n",
    "        print(\"âœ… Session configuration sent\")\n",
    "        print(f\"   Instructions: {session_config['session']['instructions'][:50]}...\")\n",
    "        print(f\"   Voice: {session_config['session']['voice']['name']}\")\n",
    "        \n",
    "        # 3. Wait a moment to receive session.created event\n",
    "        print(\"â³ Waiting for session creation...\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Check for any immediate messages\n",
    "        for i in range(5):\n",
    "            msg = connection.recv()\n",
    "            if msg:\n",
    "                try:\n",
    "                    event = json.loads(msg)\n",
    "                    print(f\"ğŸ“¨ Received: {event.get('type', 'unknown')}\")\n",
    "                    if event.get('type') == 'session.created':\n",
    "                        print(f\"   Session ID: {event.get('session', {}).get('id', 'unknown')}\")\n",
    "                    elif event.get('type') == 'error':\n",
    "                        print(f\"âŒ Error: {event.get('error', {})}\")\n",
    "                except:\n",
    "                    print(f\"ğŸ“¨ Raw message: {msg[:100]}...\")\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        # 4. Create and start threads with better error handling\n",
    "        print(\"ğŸ§µ Starting threads...\")\n",
    "        \n",
    "        def safe_listen_and_send_audio(connection):\n",
    "            try:\n",
    "                listen_and_send_audio(connection)\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Audio input error: {e}\")\n",
    "                stop_event.set()\n",
    "        \n",
    "        def safe_receive_audio_and_playback(connection):\n",
    "            try:\n",
    "                receive_audio_and_playback(connection)\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Audio output error: {e}\")\n",
    "                stop_event.set()\n",
    "        \n",
    "        send_thread = threading.Thread(\n",
    "            target=safe_listen_and_send_audio, \n",
    "            args=(connection,),\n",
    "            name=\"AudioInput\"\n",
    "        )\n",
    "        receive_thread = threading.Thread(\n",
    "            target=safe_receive_audio_and_playback, \n",
    "            args=(connection,),\n",
    "            name=\"AudioOutput\"\n",
    "        )\n",
    "        \n",
    "        # Start audio threads\n",
    "        send_thread.start()\n",
    "        receive_thread.start()\n",
    "        \n",
    "        print(\"ğŸ™ï¸  Voice chat is now active!\")\n",
    "        print(\"ğŸ’¬ You can start speaking...\")\n",
    "        print(\"ğŸ“Š Monitoring audio threads...\")\n",
    "        \n",
    "        # Monitor threads instead of waiting for keyboard input\n",
    "        start_time = time.time()\n",
    "        while not stop_event.is_set():\n",
    "            # Check if threads are still alive\n",
    "            if not send_thread.is_alive():\n",
    "                print(\"âš ï¸  Audio input thread died\")\n",
    "                break\n",
    "            if not receive_thread.is_alive():\n",
    "                print(\"âš ï¸  Audio output thread died\")\n",
    "                break\n",
    "            \n",
    "            # Print status every 10 seconds\n",
    "            if time.time() - start_time > 10:\n",
    "                print(\"ğŸ“Š Still running... Threads alive. Speak into your microphone!\")\n",
    "                start_time = time.time()\n",
    "            \n",
    "            time.sleep(1)\n",
    "        \n",
    "        # 5. Graceful shutdown\n",
    "        print(\"ğŸ›‘ Shutting down...\")\n",
    "        stop_event.set()\n",
    "        \n",
    "        # Wait for threads to finish (with timeout)\n",
    "        send_thread.join(timeout=2)\n",
    "        receive_thread.join(timeout=2)\n",
    "        \n",
    "        # Close connection\n",
    "        connection.close()\n",
    "        print(\"âœ… Voice chat ended successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in voice chat: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        stop_event.set()\n",
    "        if 'connection' in locals():\n",
    "            connection.close()\n",
    "\n",
    "print(\"âœ… Debug voice chat function created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eec6d8",
   "metadata": {},
   "source": [
    "## 18. Debug Version - Run This Instead\n",
    "\n",
    "Let's try the debug version which provides more information about what's happening:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27f60624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Checking recent logs:\n",
      "ğŸ“ Latest log file: logs/2025-08-26_18-42-15_voicelive_notebook.log\n",
      "ğŸ“„ Last 20 lines:\n",
      "2025-08-26 18:42:17,176:azure.identity._internal.decorators:DEBUG:VisualStudioCodeCredential.get_token failed: VisualStudioCodeCredential requires the 'azure-identity-broker' package to be installed. You must also ensure you have the Azure Resources extension installed and have signed in to Azure via Visual Studio Code.\n",
      "Traceback (most recent call last):\n",
      "File \"/Users/jinle/miniconda3/envs/audioagent/lib/python3.11/site-packages/azure/identity/_internal/decorators.py\", line 23, in wrapper\n",
      "token = fn(*args, **kwargs)\n",
      "^^^^^^^^^^^^^^^^^^^\n",
      "File \"/Users/jinle/miniconda3/envs/audioagent/lib/python3.11/site-packages/azure/identity/_credentials/vscode.py\", line 211, in get_token\n",
      "raise CredentialUnavailableError(message=self._unavailable_message)\n",
      "azure.identity._exceptions.CredentialUnavailableError: VisualStudioCodeCredential requires the 'azure-identity-broker' package to be installed. You must also ensure you have the Azure Resources extension installed and have signed in to Azure via Visual Studio Code.\n",
      "2025-08-26 18:42:17,176:azure.identity._credentials.azure_cli:DEBUG:Executing subprocess with the following arguments ['/opt/homebrew/bin/az', 'account', 'get-access-token', '--output', 'json', '--resource', 'https://ai.azure.com']\n",
      "2025-08-26 18:42:18,251:azure.identity._internal.decorators:DEBUG:AzureCliCredential.get_token succeeded\n",
      "2025-08-26 18:42:18,251:azure.identity._internal.decorators:DEBUG:[Authenticated account] Client ID: 04b07795-8ddb-461a-bbee-02f9e1bf7b46. Tenant ID: 9249ded8-dff5-4e90-9d80-3ae45c13ec3f. User Principal Name: admin@MngEnvMCAP166727.onmicrosoft.com. Object ID (user): d4215af3-a69c-4640-9004-3cfc07dc032f\n",
      "2025-08-26 18:42:18,251:azure.identity._credentials.chained:INFO:DefaultAzureCredential acquired a token from AzureCliCredential\n",
      "2025-08-26 18:42:18,740:websocket:INFO:Websocket connected\n",
      "2025-08-26 18:42:18,740:__main__:INFO:WebSocket connection opened\n",
      "2025-08-26 18:42:20,157:__main__:INFO:WebSocket connection closed\n",
      "2025-08-26 18:42:20,183:__main__:INFO:Starting audio stream ...\n",
      "2025-08-26 18:42:20,228:__main__:INFO:Starting audio playback ...\n",
      "2025-08-26 18:42:20,229:__main__:INFO:Session created: sess_1bakQPDxJeWOr1IwWBOCLz\n",
      "2025-08-26 18:42:28,560:__main__:INFO:Audio stream closed.\n",
      "2025-08-26 18:42:29,259:__main__:INFO:Playback done.\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Starting DEBUG voice chat...\n",
      "This version will run for a while and show more status information\n",
      "Watch for error messages and connection status\n",
      "ğŸ’¡ Uncomment the line above to run the debug version\n"
     ]
    }
   ],
   "source": [
    "# Run the debug version of voice chat\n",
    "# This will show more detailed information about what's happening\n",
    "\n",
    "# First check if we can see logs\n",
    "print(\"ğŸ“ Checking recent logs:\")\n",
    "view_logs()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸš€ Starting DEBUG voice chat...\")\n",
    "print(\"This version will run for a while and show more status information\")\n",
    "print(\"Watch for error messages and connection status\")\n",
    "\n",
    "# Uncomment the line below to run debug version:\n",
    "# run_voice_chat_debug()\n",
    "\n",
    "print(\"ğŸ’¡ Uncomment the line above to run the debug version\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc331f97",
   "metadata": {},
   "source": [
    "## 19. Quick Fix Attempts\n",
    "\n",
    "Based on the issue you're experiencing, here are the most likely causes and fixes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6f06449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Jupyter-optimized voice chat function ready!\n",
      "ğŸ’¡ This version runs for 30 seconds without keyboard input\n",
      "ğŸš€ Uncomment the line below to try it:\n",
      "# run_voice_chat_jupyter_fixed()\n"
     ]
    }
   ],
   "source": [
    "# Quick diagnostic: Check if the issue is with the keyboard input thread\n",
    "# The original code might be exiting because of input() blocking in Jupyter\n",
    "\n",
    "def run_voice_chat_jupyter_fixed():\n",
    "    \"\"\"\n",
    "    Voice chat function optimized for Jupyter notebook environment.\n",
    "    Removes the keyboard input thread that might cause issues in notebooks.\n",
    "    \"\"\"\n",
    "    global stop_event\n",
    "    \n",
    "    # Reset the stop event for a fresh start\n",
    "    stop_event.clear()\n",
    "    \n",
    "    try:\n",
    "        print(\"ğŸš€ Starting Voice Live chat application (JUPYTER OPTIMIZED)...\")\n",
    "        \n",
    "        # 1. Connect to the API\n",
    "        if hasattr(client, '_connection'):\n",
    "            connection = client._connection\n",
    "        else:\n",
    "            connection = client.connect(model=AZURE_VOICE_LIVE_MODEL)\n",
    "        print(\"âœ… Connected to Voice Live API\")\n",
    "        \n",
    "        # 2. Send session configuration\n",
    "        connection.send(json.dumps(session_config))\n",
    "        print(\"âœ… Session configuration sent\")\n",
    "        \n",
    "        # 3. Create and start threads (NO KEYBOARD THREAD)\n",
    "        print(\"ğŸ§µ Starting audio threads...\")\n",
    "        send_thread = threading.Thread(\n",
    "            target=listen_and_send_audio, \n",
    "            args=(connection,),\n",
    "            name=\"AudioInput\"\n",
    "        )\n",
    "        receive_thread = threading.Thread(\n",
    "            target=receive_audio_and_playback, \n",
    "            args=(connection,),\n",
    "            name=\"AudioOutput\"\n",
    "        )\n",
    "\n",
    "        # Start all threads\n",
    "        send_thread.start()\n",
    "        receive_thread.start()\n",
    "        \n",
    "        print(\"ğŸ™ï¸  Voice chat is now active!\")\n",
    "        print(\"ğŸ’¬ You can start speaking...\")\n",
    "        print(\"â° This will run for 30 seconds, then auto-stop\")\n",
    "        print(\"ğŸ›‘ To stop early, interrupt the kernel\")\n",
    "        \n",
    "        # Run for 30 seconds instead of waiting for keyboard\n",
    "        start_time = time.time()\n",
    "        while time.time() - start_time < 30 and not stop_event.is_set():\n",
    "            # Check threads are alive\n",
    "            if not send_thread.is_alive():\n",
    "                print(\"âš ï¸  Audio input thread stopped\")\n",
    "                break\n",
    "            if not receive_thread.is_alive():\n",
    "                print(\"âš ï¸  Audio output thread stopped\")\n",
    "                break\n",
    "            \n",
    "            # Print periodic status\n",
    "            elapsed = int(time.time() - start_time)\n",
    "            if elapsed % 5 == 0:\n",
    "                print(f\"â±ï¸  Running... {elapsed}s elapsed. Speak into microphone!\")\n",
    "            \n",
    "            time.sleep(1)\n",
    "        \n",
    "        # 5. Graceful shutdown\n",
    "        print(\"ğŸ›‘ Shutting down...\")\n",
    "        stop_event.set()\n",
    "        \n",
    "        # Wait for threads to finish (with timeout)\n",
    "        send_thread.join(timeout=2)\n",
    "        receive_thread.join(timeout=2)\n",
    "        \n",
    "        # Close connection\n",
    "        connection.close()\n",
    "        print(\"âœ… Voice chat ended successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in voice chat: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        stop_event.set()\n",
    "        if 'connection' in locals():\n",
    "            connection.close()\n",
    "\n",
    "# Try this version optimized for Jupyter:\n",
    "print(\"ğŸ”§ Jupyter-optimized voice chat function ready!\")\n",
    "print(\"ğŸ’¡ This version runs for 30 seconds without keyboard input\")\n",
    "print(\"ğŸš€ Uncomment the line below to try it:\")\n",
    "print(\"# run_voice_chat_jupyter_fixed()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853ac51f",
   "metadata": {},
   "source": [
    "## 20. Enhanced Audio Input Debugging\n",
    "\n",
    "Let's test the audio input step by step to identify the exact issue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8429b31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Step 1: Testing basic microphone access...\n",
      "Available audio devices:\n",
      "  Input Device 1: Jinâ€™s AirPods Pro (channels: 1, sample rate: 24000.0)\n",
      "  Input Device 4: HD Pro Webcam C920 (channels: 2, sample rate: 16000.0)\n",
      "  Input Device 6: Jabra Link 380 (channels: 1, sample rate: 16000.0)\n",
      "  Input Device 7: MacBook Pro Microphone (channels: 1, sample rate: 48000.0)\n",
      "  Input Device 9: Microsoft Teams Audio (channels: 1, sample rate: 48000.0)\n",
      "\n",
      "Default input device: Jinâ€™s AirPods Pro\n",
      "\n",
      "ğŸ¤ Testing 3-second recording...\n",
      "Please speak now!\n",
      "âœ… Recording complete! Max amplitude: 31\n",
      "âš ï¸  Very low audio detected - check microphone settings\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Test basic microphone access\n",
    "print(\"ğŸ” Step 1: Testing basic microphone access...\")\n",
    "\n",
    "try:\n",
    "    # Test if we can access the microphone at all\n",
    "    import sounddevice as sd\n",
    "    import numpy as np\n",
    "    \n",
    "    print(\"Available audio devices:\")\n",
    "    for i, device in enumerate(sd.query_devices()):\n",
    "        if device['max_input_channels'] > 0:\n",
    "            print(f\"  Input Device {i}: {device['name']} (channels: {device['max_input_channels']}, sample rate: {device['default_samplerate']})\")\n",
    "    \n",
    "    print(f\"\\nDefault input device: {sd.query_devices(sd.default.device[0])['name']}\")\n",
    "    \n",
    "    # Test basic recording\n",
    "    print(\"\\nğŸ¤ Testing 3-second recording...\")\n",
    "    print(\"Please speak now!\")\n",
    "    \n",
    "    duration = 3  # seconds\n",
    "    sample_rate = 24000\n",
    "    \n",
    "    recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype='int16')\n",
    "    sd.wait()  # Wait until recording is finished\n",
    "    \n",
    "    # Check if we got any audio\n",
    "    max_amplitude = np.max(np.abs(recording))\n",
    "    print(f\"âœ… Recording complete! Max amplitude: {max_amplitude}\")\n",
    "    \n",
    "    if max_amplitude > 100:  # Some reasonable threshold\n",
    "        print(\"âœ… Microphone is working - detected audio!\")\n",
    "    else:\n",
    "        print(\"âš ï¸  Very low audio detected - check microphone settings\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Microphone test failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "469c592c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Enhanced audio input function created\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Create an enhanced audio input function with debugging\n",
    "def listen_and_send_audio_debug(connection: VoiceLiveConnection) -> None:\n",
    "    \"\"\"\n",
    "    Enhanced version of audio input function with detailed debugging.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ¤ [AUDIO INPUT] Starting enhanced audio stream with debugging...\")\n",
    "\n",
    "    # Create audio input stream\n",
    "    stream = sd.InputStream(\n",
    "        channels=1, \n",
    "        samplerate=AUDIO_SAMPLE_RATE, \n",
    "        dtype=\"int16\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        stream.start()\n",
    "        print(f\"ğŸ¤ [AUDIO INPUT] Stream started successfully at {AUDIO_SAMPLE_RATE}Hz\")\n",
    "        \n",
    "        # Read audio in 20ms chunks (480 samples at 24kHz)\n",
    "        read_size = int(AUDIO_SAMPLE_RATE * 0.02)\n",
    "        print(f\"ğŸ¤ [AUDIO INPUT] Reading chunks of {read_size} samples ({20}ms)\")\n",
    "        \n",
    "        chunk_count = 0\n",
    "        audio_sent_count = 0\n",
    "        last_activity_time = time.time()\n",
    "        \n",
    "        while not stop_event.is_set():\n",
    "            if stream.read_available >= read_size:\n",
    "                # Read audio data\n",
    "                data, overflowed = stream.read(read_size)\n",
    "                chunk_count += 1\n",
    "                \n",
    "                if overflowed:\n",
    "                    print(\"âš ï¸  [AUDIO INPUT] Audio buffer overflow detected!\")\n",
    "                \n",
    "                # Check audio level\n",
    "                audio_level = np.max(np.abs(data))\n",
    "                \n",
    "                # Log activity every 5 seconds or when there's significant audio\n",
    "                current_time = time.time()\n",
    "                if audio_level > 500 or (current_time - last_activity_time) > 5:\n",
    "                    print(f\"ğŸ¤ [AUDIO INPUT] Chunk {chunk_count}: level={audio_level}, available={stream.read_available}\")\n",
    "                    last_activity_time = current_time\n",
    "                \n",
    "                # Encode as base64\n",
    "                audio = base64.b64encode(data).decode(\"utf-8\")\n",
    "                \n",
    "                # Create API message\n",
    "                param = {\n",
    "                    \"type\": \"input_audio_buffer.append\", \n",
    "                    \"audio\": audio, \n",
    "                    \"event_id\": \"\"\n",
    "                }\n",
    "                \n",
    "                # Send to API\n",
    "                try:\n",
    "                    data_json = json.dumps(param)\n",
    "                    connection.send(data_json)\n",
    "                    audio_sent_count += 1\n",
    "                    \n",
    "                    # Log significant audio being sent\n",
    "                    if audio_level > 500:\n",
    "                        print(f\"ğŸ”Š [AUDIO INPUT] Sent significant audio chunk (level={audio_level}) - total sent: {audio_sent_count}\")\n",
    "                        \n",
    "                except Exception as send_error:\n",
    "                    print(f\"âŒ [AUDIO INPUT] Failed to send audio: {send_error}\")\n",
    "                    \n",
    "            else:\n",
    "                time.sleep(0.001)  # Small sleep to prevent busy waiting\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ [AUDIO INPUT] Audio stream error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        stream.stop()\n",
    "        stream.close()\n",
    "        print(f\"ğŸ¤ [AUDIO INPUT] Stream closed. Total chunks processed: {chunk_count}, sent: {audio_sent_count}\")\n",
    "\n",
    "print(\"âœ… Enhanced audio input function created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f6218a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Full debug voice chat function ready!\n",
      "ğŸ” This version will show exactly what's happening with audio input/output\n",
      "ğŸš€ Run: run_voice_chat_full_debug()\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Enhanced voice chat with comprehensive debugging\n",
    "def run_voice_chat_full_debug():\n",
    "    \"\"\"\n",
    "    Fully instrumented voice chat for debugging audio input issues.\n",
    "    \"\"\"\n",
    "    global stop_event\n",
    "    \n",
    "    # Reset the stop event for a fresh start\n",
    "    stop_event.clear()\n",
    "    \n",
    "    try:\n",
    "        print(\"ğŸš€ Starting FULL DEBUG Voice Live chat application...\")\n",
    "        \n",
    "        # 1. Connect to the API\n",
    "        connection = client._connection\n",
    "        print(\"âœ… Connected to Voice Live API\")\n",
    "        \n",
    "        # 2. Send session configuration\n",
    "        connection.send(json.dumps(session_config))\n",
    "        print(\"âœ… Session configuration sent\")\n",
    "        \n",
    "        # 3. Wait and check for session.created\n",
    "        print(\"â³ Waiting for session.created event...\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "        initial_messages = []\n",
    "        for i in range(5):\n",
    "            msg = connection.recv()\n",
    "            if msg:\n",
    "                try:\n",
    "                    event = json.loads(msg)\n",
    "                    initial_messages.append(event)\n",
    "                    print(f\"ğŸ“¨ Initial message {i+1}: {event.get('type', 'unknown')}\")\n",
    "                except:\n",
    "                    print(f\"ğŸ“¨ Raw initial message {i+1}: {msg[:100]}...\")\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        print(f\"ğŸ“¨ Received {len(initial_messages)} initial messages\")\n",
    "        \n",
    "        # 4. Enhanced audio output function\n",
    "        def receive_audio_and_playback_debug(connection):\n",
    "            \"\"\"Enhanced audio output with debugging.\"\"\"\n",
    "            print(\"ğŸ”Š [AUDIO OUTPUT] Starting enhanced audio playback thread...\")\n",
    "            last_audio_item_id = None\n",
    "            audio_player = AudioPlayerAsync()\n",
    "            message_count = 0\n",
    "            \n",
    "            try:\n",
    "                while not stop_event.is_set():\n",
    "                    raw_event = connection.recv()\n",
    "                    if raw_event is None:\n",
    "                        continue\n",
    "                    \n",
    "                    message_count += 1\n",
    "                    try:\n",
    "                        event = json.loads(raw_event)\n",
    "                        event_type = event.get(\"type\")\n",
    "                        print(f\"ğŸ”Š [AUDIO OUTPUT] Message {message_count}: {event_type}\")\n",
    "\n",
    "                        if event_type == \"session.created\":\n",
    "                            session = event.get(\"session\")\n",
    "                            print(f\"ğŸ”Š [AUDIO OUTPUT] Session created: {session.get('id')}\")\n",
    "\n",
    "                        elif event_type == \"response.audio.delta\":\n",
    "                            if event.get(\"item_id\") != last_audio_item_id:\n",
    "                                last_audio_item_id = event.get(\"item_id\")\n",
    "                                print(f\"ğŸ”Š [AUDIO OUTPUT] New audio item: {last_audio_item_id}\")\n",
    "\n",
    "                            bytes_data = base64.b64decode(event.get(\"delta\", \"\"))\n",
    "                            if bytes_data:\n",
    "                                print(f\"ğŸ”Š [AUDIO OUTPUT] Playing {len(bytes_data)} bytes of audio\")   \n",
    "                                audio_player.add_data(bytes_data)\n",
    "\n",
    "                        elif event_type == \"input_audio_buffer.speech_started\":\n",
    "                            print(\"ğŸ¤ [AUDIO OUTPUT] Speech started detected - stopping playback\")\n",
    "                            audio_player.stop()\n",
    "                            \n",
    "                        elif event_type == \"input_audio_buffer.speech_stopped\":\n",
    "                            print(\"ğŸ¤ [AUDIO OUTPUT] Speech stopped detected\")\n",
    "\n",
    "                        elif event_type == \"error\":\n",
    "                            error_details = event.get(\"error\", {})\n",
    "                            print(f\"âŒ [AUDIO OUTPUT] API Error: {error_details}\")\n",
    "                            \n",
    "                        # Log any other interesting events\n",
    "                        elif event_type in [\"response.created\", \"response.done\", \"conversation.item.created\"]:\n",
    "                            print(f\"ğŸ“ [AUDIO OUTPUT] Event: {event_type}\")\n",
    "                            \n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"âŒ [AUDIO OUTPUT] JSON decode error: {e}\")\n",
    "                        continue\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ [AUDIO OUTPUT] Error: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "            finally:\n",
    "                audio_player.terminate()\n",
    "                print(f\"ğŸ”Š [AUDIO OUTPUT] Thread ended. Processed {message_count} messages\")\n",
    "        \n",
    "        # 5. Start threads with enhanced functions\n",
    "        print(\"ğŸ§µ Starting enhanced audio threads...\")\n",
    "        \n",
    "        send_thread = threading.Thread(\n",
    "            target=listen_and_send_audio_debug, \n",
    "            args=(connection,),\n",
    "            name=\"AudioInputDebug\"\n",
    "        )\n",
    "        receive_thread = threading.Thread(\n",
    "            target=receive_audio_and_playback_debug, \n",
    "            args=(connection,),\n",
    "            name=\"AudioOutputDebug\"\n",
    "        )\n",
    "\n",
    "        send_thread.start()\n",
    "        receive_thread.start()\n",
    "        \n",
    "        print(\"ğŸ™ï¸  FULL DEBUG voice chat is active!\")\n",
    "        print(\"ğŸ’¬ Speak into your microphone - you should see detailed logging\")\n",
    "        print(\"â° Running for 20 seconds with enhanced monitoring...\")\n",
    "        \n",
    "        # Run for 20 seconds with detailed monitoring\n",
    "        start_time = time.time()\n",
    "        while time.time() - start_time < 20 and not stop_event.is_set():\n",
    "            elapsed = int(time.time() - start_time)\n",
    "            \n",
    "            # Check thread health every 2 seconds\n",
    "            if elapsed % 2 == 0:\n",
    "                send_alive = send_thread.is_alive()\n",
    "                receive_alive = receive_thread.is_alive()\n",
    "                print(f\"â±ï¸  [{elapsed}s] Threads - Input: {'âœ…' if send_alive else 'âŒ'}, Output: {'âœ…' if receive_alive else 'âŒ'}\")\n",
    "                \n",
    "                if not send_alive or not receive_alive:\n",
    "                    print(\"âš ï¸  Thread died - stopping...\")\n",
    "                    break\n",
    "            \n",
    "            time.sleep(1)\n",
    "        \n",
    "        # 6. Graceful shutdown\n",
    "        print(\"ğŸ›‘ Shutting down full debug session...\")\n",
    "        stop_event.set()\n",
    "        \n",
    "        send_thread.join(timeout=3)\n",
    "        receive_thread.join(timeout=3)\n",
    "        \n",
    "        connection.close()\n",
    "        print(\"âœ… Full debug voice chat ended\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Full debug error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        stop_event.set()\n",
    "        if 'connection' in locals():\n",
    "            connection.close()\n",
    "\n",
    "print(\"âœ… Full debug voice chat function ready!\")\n",
    "print(\"ğŸ” This version will show exactly what's happening with audio input/output\")\n",
    "print(\"ğŸš€ Run: run_voice_chat_full_debug()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8a9a669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ENVIRONMENT ANALYSIS\n",
      "==================================================\n",
      "ğŸ Python: 3.11.13 | packaged by conda-forge | (main, Jun  4 2025, 14:52:34) [Clang 18.1.8 ]\n",
      "ğŸ’» Platform: macOS-15.6-arm64-arm-64bit\n",
      "ğŸ  Running in: Unknown\n",
      "\n",
      "ğŸ”Š AUDIO LIBRARIES\n",
      "------------------------------\n",
      "âœ… sounddevice: 0.5.2\n",
      "âŒ sounddevice error: module 'sounddevice' has no attribute 'get_audio_backends'\n",
      "âœ… numpy: 2.3.2\n",
      "\n",
      "ğŸ™ï¸ AUDIO DEVICES\n",
      "------------------------------\n",
      "ğŸ“± Total devices: 10\n",
      "ğŸ¤ Default input device: 1\n",
      "ğŸ”Š Default output device: 2\n",
      "\n",
      "ğŸ¤ Input devices (5):\n",
      "   0: Jinâ€™s AirPods Pro (channels: 1)\n",
      "â­ 1: HD Pro Webcam C920 (channels: 2)\n",
      "   2: Jabra Link 380 (channels: 1)\n",
      "   3: MacBook Pro Microphone (channels: 1)\n",
      "   4: Microsoft Teams Audio (channels: 1)\n",
      "\n",
      "ğŸ” PERMISSION CHECK\n",
      "------------------------------\n",
      "âœ… Microphone access test: SUCCESS\n",
      "ğŸ“Š Sample data shape: (1, 1)\n",
      "\n",
      "ğŸ§µ THREADING INFO\n",
      "------------------------------\n",
      "ğŸ§µ Active threads: 8\n",
      "   â€¢ MainThread (alive)\n",
      "   â€¢ IOPub (alive)\n",
      "   â€¢ Heartbeat (alive)\n",
      "   â€¢ Thread-1 (_watch_pipe_fd) (alive)\n",
      "   â€¢ Thread-2 (_watch_pipe_fd) (alive)\n",
      "   â€¢ Control (alive)\n",
      "   â€¢ IPythonHistorySavingThread (alive)\n",
      "   â€¢ Dummy-5 (alive)\n",
      "\n",
      "âœ… Environment analysis complete!\n"
     ]
    }
   ],
   "source": [
    "## ğŸ“‹ Section 22: Environment and Permission Analysis\n",
    "\n",
    "def analyze_environment():\n",
    "    \"\"\"\n",
    "    Comprehensive environment analysis for audio troubleshooting.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ” ENVIRONMENT ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Python environment\n",
    "    import sys\n",
    "    import platform\n",
    "    print(f\"ğŸ Python: {sys.version}\")\n",
    "    print(f\"ğŸ’» Platform: {platform.platform()}\")\n",
    "    print(f\"ğŸ  Running in: {'Jupyter' if 'jupyter' in sys.modules else 'Unknown'}\")\n",
    "    \n",
    "    # 2. Check audio libraries\n",
    "    print(\"\\nğŸ”Š AUDIO LIBRARIES\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    try:\n",
    "        import sounddevice as sd\n",
    "        print(f\"âœ… sounddevice: {sd.__version__}\")\n",
    "        print(f\"ğŸ“š sounddevice backend: {sd.get_audio_backends()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ sounddevice error: {e}\")\n",
    "    \n",
    "    try:\n",
    "        import numpy as np\n",
    "        print(f\"âœ… numpy: {np.__version__}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ numpy error: {e}\")\n",
    "    \n",
    "    # 3. Audio device information\n",
    "    print(\"\\nğŸ™ï¸ AUDIO DEVICES\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    try:\n",
    "        devices = sd.query_devices()\n",
    "        print(f\"ğŸ“± Total devices: {len(devices)}\")\n",
    "        \n",
    "        default_input = sd.default.device[0] if sd.default.device[0] is not None else \"None\"\n",
    "        default_output = sd.default.device[1] if sd.default.device[1] is not None else \"None\"\n",
    "        \n",
    "        print(f\"ğŸ¤ Default input device: {default_input}\")\n",
    "        print(f\"ğŸ”Š Default output device: {default_output}\")\n",
    "        \n",
    "        # Show input devices specifically\n",
    "        input_devices = [d for d in devices if d['max_input_channels'] > 0]\n",
    "        print(f\"\\nğŸ¤ Input devices ({len(input_devices)}):\")\n",
    "        for i, device in enumerate(input_devices):\n",
    "            star = \"â­\" if i == default_input else \"  \"\n",
    "            print(f\"{star} {i}: {device['name']} (channels: {device['max_input_channels']})\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Audio device query error: {e}\")\n",
    "    \n",
    "    # 4. Check for potential permission issues\n",
    "    print(\"\\nğŸ” PERMISSION CHECK\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    try:\n",
    "        # Try to open default input briefly\n",
    "        with sd.InputStream(samplerate=24000, channels=1, dtype='int16') as stream:\n",
    "            data, _ = stream.read(1)  # Read 1 frame\n",
    "            print(\"âœ… Microphone access test: SUCCESS\")\n",
    "            print(f\"ğŸ“Š Sample data shape: {data.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Microphone access test: FAILED\")\n",
    "        print(f\"   Error: {e}\")\n",
    "        print(\"   This might indicate permission issues!\")\n",
    "    \n",
    "    # 5. Memory and threading info\n",
    "    print(\"\\nğŸ§µ THREADING INFO\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    import threading\n",
    "    active_threads = threading.active_count()\n",
    "    print(f\"ğŸ§µ Active threads: {active_threads}\")\n",
    "    \n",
    "    for thread in threading.enumerate():\n",
    "        print(f\"   â€¢ {thread.name} ({'alive' if thread.is_alive() else 'dead'})\")\n",
    "    \n",
    "    print(\"\\nâœ… Environment analysis complete!\")\n",
    "\n",
    "# Run the analysis\n",
    "analyze_environment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audioagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
